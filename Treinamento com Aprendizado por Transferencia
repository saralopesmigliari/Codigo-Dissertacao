
# -*- coding: utf-8 -*-
"""Arquitetura Treinamento com Aprendizado por Transferência

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yeyj_4KH3DYMiMnsZSUfFlleGUGhFnWm

###INÍCIO
"""

# DIRETÓRIO

from google.colab import drive
drive.mount('/content/drive')

# IMPORTAÇÕES

from PIL import Image
from os import listdir
from os.path import isdir
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.image import ImageDataGenerator #(TÉCNICA PARA AUMENTAR A QUANTIDADE DE IMAGENS QUE JÁ POSSUE)
from tensorflow.keras.applications import VGG19 #(UM DOS TIPOS DE APLICAÇÕES, UMA CNN JÁ PRONTA)
from tensorflow.keras.utils import to_categorical
from keras.layers import Conv2D #(CAMADAS DE CONVOLUÇÃO)
from keras.layers import MaxPooling2D #(CAMADAS DE POOLING)
from tensorflow.keras import layers
from tensorflow.keras import models
from tensorflow.keras import optimizers
from sklearn.metrics import classification_report

# CARREGAMENTO DAS IMAGENS

def select_image(filename): #CARREGA A IMAGEM
    image = Image.open(filename) #ABRE O ARQUIVO
    image = image.convert('RGB') #CONVERTE A IMAGEM PARA RGB
    image = image.resize((299,299)) #REDIMENSIONANDO OS PIXELS DAS IMAGENS

    return np.asarray(image) #VOLTA A IMAGEM COMO UM ARRAY PELA FUNÇÃO DA BIBLIOTECA NUMPY

"""**Carregamento de classes:**

Utilizando a função para selecionar uma pasta de dataset com imagens e suas respectivas classes, em resumo a função nomeia cada um dos arquivos de imagens com sua devida classe.
"""

def load_class(diretorio, classe, imagens, labels): #INTERANDO ARQUIVOS

    for filename in listdir(diretorio):

        path = diretorio + filename

        try:
            imagens.append(select_image(path))
            labels.append(classe)
        except:
            print("Erro ao ler imagem {}".format(path))

    return imagens, labels

"""**Seleção do Dataset:**

Essa função explica para o algoritmo o que é levado em consideração sobre o que é um diretório.
"""

def select_data_set(diretorio):

    imagens = list()
    labels = list()

    for subdir in listdir(diretorio):

        path = diretorio + subdir + '/'

        if not isdir(path):
            continue
        imagens, labels = load_class(path, subdir, imagens, labels)

    return imagens, labels

"""Realizando o carregamento do dataset e normalizando:


"""

base_dataset = "/content/drive/MyDrive/PROJETO_DANILO/IMAGEM FOLHAS - SEGMENTADO/Binary/"
imagens, labels = select_data_set(base_dataset)

imagens = np.array(imagens) / 255.0  #CONVERTE LISTA PARA ARRAY
labels = np.array(labels)  #CONVERTE LISTA PARA ARRAY

labels[1] #PARA TESTE, PRINT DE UMA POSIÇÃO DA CLASSE

"""**Tratando as classes das imagens:**

Ex: labels [0] # O número 0 informado representa a classe que está inserida na posição 0, o mesmo valerá para a classe que estiver na posição 100 por exemplo, se o problema tiver 100 ou mais classes

imagens [1] # O número 0 informado representa a imagem que está inserida na posição 0, o mesmo valerá para a imagem que estiver na posição 100 por exemplo, se o problema tiver 100 ou mais imagens
"""

# CATEGORIZAÇÃO

lb = LabelEncoder() #BIBLIOTECA QUE APLICA A BINALIZAÇÃO DA IMAGEM
labels = lb.fit_transform(labels)
labels = to_categorical(labels) #CATEGORIZA LABELS (KERAS EXIGE)

"""**Definindo hiperparâmetros:**

Parâmetros da RNA que você irá utilizar.
"""

batch_size = 16 #QUANTIDADE DE IMAGENS POR LOTES PROCESSADO POR VEZ, EXEMPLO SEPARANDO UMA QUANTIDADE X DE IMAGENS POR PACOTE
input_shape = (299, 299, 3) #TAMANHO DA ENTRADA
random_state = 42 #REPRODUÇÃO DA EXPERIÊNCIA
alpha       = 0.001 #TAXA DE APRENDIZADO
epoch       = 100 #QUANTIDADE DE ÉPOCAS, QUANTIDADE DE VX QUE O TREINAMENTO É REPETIDO

from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau #BIBLIOTECA USADA PARA SALVAR A ARQUITETURA COM O MELHOR RESULTADO

"""**Callbacks**

ModelCheckpoint - É modelo que ajuda a salvar o modelo durante o treinamento, época por época realiza o salvamento para o caso de ocorrer algum erro no decorrer da execução do treinamento e perder os dados

ReduceLROnPlateau - Função utilizada para que com a descida do gradiente, o algoritmo não trave em um plato ou um mínimo local, auxiliando o algoritmo na procura pelo melhor resultado. Obs: É uma técnica que auxilia significativamente no valor da acurácia final do algoritmo.
"""

filepath="nomedoarquivo.hdf5" #ONDE SALVA O MODELO DE PESOS DA ARQUITETURA TREINADA

checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')
#MÉTRICA DE AVALIAÇÃO MONITORADA, EX: ACURÁCIA.
#VERBOSE SE USA PRA EXIBIR BARRA DE PROGRESSO (1 MOSTRA/0 NÃO MOSTRA)
#SAVE_BEST_ONLY SÓ O MELHOR RESULTADO = TRUE OS FALSE
#MODE VISUALIZA O VALOR MÁXIMO DA ACURÁCIA

lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=alpha, patience=5, verbose=1)
#FACTOR, FATOR DE REDUÇÃO, CASO OCORRE O PLATÔ, MIN_DELTA INDICARÁ O VALOR DE PERDA MÍNIMA
#PATIENCE QUANTIDADE DE VEZES EM QUE A ACURÁCIA É REPETIDA PARA MUDAR A TAXA DE APRENDIZADO DO REDUCION PLATÔ

# ARRAY DE CALLBACKS

callbacks = [checkpoint, lr_reduce]

# ENCAMINHA PARA O SPLIT DE TESTE E TREINO

(trainX, testX, trainY, testY) = train_test_split(imagens, labels, test_size=0.2, stratify=labels, random_state=random_state)
# SE UTILIZA A BIBLIOTECA SCIKITLEARN, PODENDO SER 80% PARA TREINO E 20% PARA TESTE
# ESTRATIFICA LABELS SEPARA POR CLASSE NO TREINAMENTO E TESTE

"""**Data Augmentation:**

Realiza o aumento dos dados, transformando uma imagens em várias outras de diferentes posições, flipando, espelhando, inclinando, rotacionando e etc.
"""

train_datagen = ImageDataGenerator(
    rotation_range=20, #ROTACIONA A IMAGEM
    zoom_range=0.2) #APROXIMA OU AFASTA A IMAGEM

train_datagen.fit(trainX) #TREINAMENTO SOMENTE DA BASE DE TREINO AMPLIADA COM O DA

data_aug = train_datagen.flow(trainX, trainY, batch_size=batch_size) #SERVE PRO ALGORITMO TREINA AS NOVAS VARIAÇÕES DE IMAGENS DA BASE DE DADOS GERADAS

"""**TRANSFER LEARNING**

Utiliza-se de base de dados já prontas provindas de outros algoritmos que visavam a solução de outros problemas para aplicar em outros algoritmos de Redes Neurais ou Redes Neurais convolucionais, para aprimorar e obter cada vez mais melhores resultados.

Exemplo disso seria a Alexnet, Incepcion, VGG19 que é a usada neste algoritmo como exemplo. A VGG19 é boa para extrair Features.
"""

conv_base = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)
# Weights são os pesos utilizados de onde foi inicialmente aplicado essa rede.
#include_top: se deve incluir ou não a camada totalmente conectada na parte superior da rede. input_shape é o formato da imagem, no caso deste problema anteriormente foi definido 150x150, então se fará uso do mesmo artifício com a mesma configuração.

conv_base.summary()

"""**Retreinamento da Rede**

AJUSTE FINO - Como as camadas iniciais de uma Rede convolucional aprende características mais gerais do problema, é válido congelar estas camadas e retreinar apenas as camadas mais profundas que aprendem características mais específicas.

**Duas limitações do ajuste fino:**

A quantidade de dados necessária para o treinamento não precisa ser tão grande, porém pode-se dar mais capacidade de entendimento a rede pré-treinada. Segundo, a parte que está sendo retreinada não é treinada do zero. Como os parâmetros que precisam ser atualizados são menores, a quantidade de tempo de processamento necessária também será menor.
"""

conv_base.trainable = True  # Com este comando você retreina parte da rede convolucional Xception a partir do Bloco 5
set_trainable = False

for layer in conv_base.layers:
  if layer.name == 'conv2_block1_1_conv':#'block5_conv1':
    set_trainable = True
  if set_trainable:
    layer.trainable = True
  else:
    layer.trainable = False

conv_base.summary()

"""Criando Modelo próprio baseado em Rede utilizando o Keras:

"""

model = models.Sequential() # Setando modelo Sequencial
model.add(conv_base) # Adcionando o modelo do TransferLearning do Xception
model.add(layers.GlobalAveragePooling2D()) # Realizando o pooling pela média global
model.add(layers.BatchNormalization()) # O BatchNormalization é utilizado para aumentar a estabilidade da rede neural, aplicando normalizações durante o treinamento
model.add(layers.Flatten()) # Transforma a Matriz em um vetor
#model.add(layers.Dense(512, activation='relu')) # Camada densa com 512 neuronios e função de ativação relu
#model.add(layers.Dense(256, activation='relu')) # Camada densa com 256 neuronios e função de ativação relu
#model.add(layers.Dense(64, activation='relu')) # Camada densa com 128 neuronios e função de ativação relu
model.add(layers.Dense(32, activation='relu')) # Camada densa com 64 neuronios e função de ativação relu
#model.add(layers.Dense(16, activation='relu')) # Camada densa com 32 neuronios e função de ativação relu
model.add(layers.Dropout(0.3)) # Dropout serve para que o algoritmo possa generalizar e regularizar melhor, ele realiza isto inativando a quantidade informada de neurônios que se deseja desligar, diminuindo o Overfitting
model.add(layers.Dense(8, activation='softmax')) # Camada densa com 2 neurônios, pois só existem duas prováveis saídas para este problema, com a função de

model.summary()

"""**TREINAMENTO**"""

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['acc'])

history = model.fit_generator(
                              data_aug,
                              steps_per_epoch=len(trainX)//batch_size,
                              validation_data=(testX, testY),
                              validation_steps=len(testX)//batch_size,
                              callbacks=callbacks,
                              epochs=epoch)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

plt.plot(history.history['acc'])
#plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Sumarizar o histórico por perda

plt.plot(history.history['loss'])
#plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

from sklearn.metrics import confusion_matrix
pred = model.predict(testX)
pred = np.argmax(pred,axis = 1)
y_true = np.argmax(testY, axis = 1)

cm = confusion_matrix(y_true, pred)
total = sum(sum(cm))
acc = (cm[0, 0] + cm[1, 1] + cm[2, 2] + cm[3, 3] + cm[4, 4] + cm[5, 5]) / total
#sensitivity = cm[0, 0] / (cm[0, 0] + cm[1, 1])
#specificity = cm[1, 1] / (cm[0, 0] + cm[1, 1])

print("Acurácia: {:.4f}".format(acc))
#print("Sensitividade: {:.4f}".format(sensitivity))
#print("Especificidade: {:.4f}".format(specificity))

from mlxtend.plotting import plot_confusion_matrix
fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(5, 5))
plt.show()

scores = model.evaluate(testX, testY, verbose=0)
print("\nacc: %.2f%%" % (scores[1]*100))

print(classification_report(y_true, pred))
